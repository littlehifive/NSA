---
title: "Bayesian analysis"
author: "Michael Wu"
date: "2023-01-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data preparation

```{r data preparation, include = F}
library(tidyverse)
library(targets)
library(brms)
library(mice)
library(bayestestR)
library(performance)
library(broom.mixed)
library(lme4)
library(bayesplot)
library(interactions)

source("R/functions.R")

# stan option
options(mc.cores = parallel::detectCores())

# reversed coded master dataset
# dat <- tar_read(dat_all_cleaned_reverse_coded)

# combine coded master dataset
dat_t <- tar_read(dat_all_cleaned_combine_coded)

# combine coded master dataset with fscores
dat_fs <- tar_read(dat_all_cleaned_combine_coded_fscore)
```

# Multiple imputation

## Using average scores
```{r}
dat_s <- dat_t |> filter(!is.na(treated_int))

dat_s <- dat_s |> 
  rowwise() |> 
  mutate(
    # self integrity and self-esteem
    self_integrity_esteem_b = mean(c(capable_person_b, confident_abt_future_b, comfortable_who_i_am_b, feel_smart_b, respect_lookup_b), na.rm = T),
    self_integrity_esteem_e = mean(c(capable_person_e, confident_abt_future_e, comfortable_who_i_am_e, feel_smart_e, respect_lookup_e), na.rm = T),
    
    # belonging
    belonging_b = mean(c(belong_school_b, people_accept_b, comfortable_at_school_b, ppl_like_me_b), na.rm = T),
    belonging_e = mean(c(belong_school_e, people_accept_e, comfortable_at_school_e, ppl_like_me_e), na.rm = T),
    
    # perceived stereotype
    worry_b = mean(c(worry_abt_dumb_b, nervous_worried_b, worry_ppl_dislike_b, concerned_abt_impression_b,worried_other_think_b), na.rm = T),
    worry_e = mean(c(worry_abt_dumb_e, nervous_worried_e, worry_ppl_dislike_e,concerned_abt_impression_e,worried_other_think_e), na.rm = T),
    
    # stereotype threat (combined)
    stereotype_b = mean(c(conclusion_other_deaf_b, conclusion_my_perform_b, conclusion_abt_me_b), na.rm = T),
    stereotype_e = mean(c(conclusion_other_deaf_e, conclusion_my_perform_e, conclusion_abt_me_e), na.rm = T),
    
    # all stereotype related items together
    stereotype_all_b = mean(c(worry_abt_dumb_b, nervous_worried_b, worry_ppl_dislike_b, concerned_abt_impression_b,worried_other_think_b, conclusion_other_deaf_b, conclusion_my_perform_b, conclusion_abt_me_b), na.rm = T),
    
    stereotype_all_e = mean(c(worry_abt_dumb_e, nervous_worried_e, worry_ppl_dislike_e, concerned_abt_impression_e,worried_other_think_e, conclusion_other_deaf_e, conclusion_my_perform_e, conclusion_abt_me_e), na.rm = T),
    
    # stereotype threat (individual item)
    
    ## conclusions about the deaf based on performance of deaf students
    threat_others2others_b = conclusion_other_deaf_b,
    threat_others2others_e = conclusion_other_deaf_e,
    
    ## conclusions about the deaf based on my performance
    threat_me2others_b = conclusion_my_perform_b,
    threat_me2others_e = conclusion_my_perform_e,
    
    ## conclusions about me based on performance of other deaf students
    threat_others2me_b = conclusion_abt_me_b,
    threat_others2me_e = conclusion_abt_me_e,
    
    # academic stress
    academic_stress_b = mean(c(bad_grades_b, not_understand_class_b,not_understand_homework_b, bad_class_teacher_b, trouble_studying_b, pressure_parent_teacher_b), na.rm = T),
    academic_stress_e = mean(c(bad_grades_e, not_understand_class_e,not_understand_homework_e, bad_class_teacher_e, trouble_studying_e, pressure_parent_teacher_e), na.rm = T)
    )

# scale within each classroom
dat_s <- dat_s |> 
  group_by(class_id) |> 
  mutate_at(vars(self_integrity_esteem_b:academic_stress_e), function(x){as.numeric(scale(x))})

dat_s <- dat_s |> select(
  
  # demographics
  st_id, grade, class_id, class_size, gender, age_b, student_type,
  father_edu_f, mother_edu_f, father_occ_salary, mother_occ_salary,
  adult_members, siblings, 
  
  # intervention variables
  treated_int, duration_int,
  mc_survey_1_int:mc_survey_4_int,
  
  # survey outcome composite
  self_integrity_esteem_b, self_integrity_esteem_e,
  belonging_b, belonging_e,
  worry_b, worry_e,
  stereotype_b, stereotype_e,
  #stereotype_all_b, stereotype_all_e,
  #threat_others2others_b, threat_me2others_b, threat_others2me_b,
  #threat_others2others_e, threat_me2others_e, threat_others2me_e,
  academic_stress_b, academic_stress_e)

# multiple imputation on data including all students  
dat_mi <- mice::mice(dat_s, m = 5, seed = 1234)

# multiple imputation on data including only deaf students
dat_s_deaf <- dat_s |> filter(student_type == "Deaf")
dat_mi_deaf <- mice::mice(dat_s_deaf, m = 5, seed = 1234)
```

## Using factor scores
```{r}
dat_s <- dat_fs |> filter(!is.na(treated_int))

# scale within each classroom
dat_s <- dat_s |> 
  group_by(class_id) |> 
  mutate_at(vars(fscore_f1_b:fscore_f3_e), function(x){as.numeric(scale(x))})

# exclude the raw survey items to prevent double-dipping in multiple imputation
dat_s <- dat_s |> select(
  st_id, sch_id, grade, class_id, class_size, gender, age_b, student_type, father_edu_f,
  mother_edu_f, father_occ_salary, mother_occ_salary, adult_members,
  siblings, treated_int, duration_int, 
  int_q1_value_1_int, int_q1_value_2_int, int_q1_value_3_int,
  mc_survey_1_int:mc_survey_4_int,
  fscore_f1_b:fscore_f3_e)

# multiple imputation on data including all students  
dat_mi <- mice::mice(dat_s, m = 5, seed = 1234)

# multiple imputation on data including only deaf students
dat_s_deaf <- dat_s |> filter(student_type == "Deaf")
dat_mi_deaf <- mice::mice(dat_s_deaf, m = 5, seed = 1234)
```

## Using factor scores + GPA data

It may not make sense to impute GPA data at all given the biases introduced (see GPT-4 answers). So for GPA analysis, I will use complete cases.

```{r}
dat_s <- dat_fs |> filter(!is.na(treated_int))

# scale within each classroom
dat_s <- dat_s |> 
  group_by(class_id) |> 
  mutate_at(vars(fscore_f1_b:fscore_f3_e), function(x){as.numeric(scale(x))})

# exclude the raw survey items to prevent double-dipping in multiple imputation
dat_s <- dat_s |> select(
  st_id, sch_id, grade, class_id, class_size, gender, age_b, student_type, father_edu_f,
  mother_edu_f, father_occ_salary, mother_occ_salary, adult_members,
  siblings, treated_int, duration_int, 
  int_q1_value_1_int, int_q1_value_2_int, int_q1_value_3_int,
  mc_survey_1_int:mc_survey_4_int,
  nepali_scores_b:science_grades_b,
  nepali_scores_e:science_grades_e,
  fscore_f1_b:fscore_f3_e)

dat_s$all_gpa_b <- rowMeans(dat_s[,c("nepali_gpa_b", "english_gpa_b", "math_gpa_b", "science_gpa_b")], na.rm = T)
dat_s$all_gpa_e <- rowMeans(dat_s[,c("nepali_gpa_e", "english_gpa_e", "math_gpa_e", "science_gpa_e")], na.rm = T)

dat_s <- dat_s |> 
  filter(!(sch_id == 3 & grade == 12)) |> 
  filter(!(sch_id == 2 & grade %in% c(11, 12))) |> 
  filter(!(sch_id == 1 & grade %in% c(11, 12)))

dat_s_deaf <- dat_s |> filter(student_type == "Deaf")
 
# grade 11 in Pokhara did not have math and science tests (but I cannot exclude the variables from imputation since there are substantial missingness in other schools)
# dat_mi_method <- mice::make.method(dat_s)
# dat_mi_method["math_gpa_b"] <- ""
# dat_mi_method["science_gpa_b"] <- ""
# dat_mi_method["math_gpa_e"] <- ""
# dat_mi_method["science_gpa_e"] <- ""

# multiple imputation on data including all students 

# dat_s_mi <- dat_s |> select(
#   st_id, sch_id, grade, class_id, class_size, gender, age_b, student_type, father_edu_f,
#   mother_edu_f, father_occ_salary, mother_occ_salary, adult_members,
#   siblings, treated_int, duration_int, 
#   # int_q1_value_1_int, int_q1_value_2_int, int_q1_value_3_int,
#   # mc_survey_1_int:mc_survey_4_int,
#   # nepali_gpa_b, english_gpa_b, math_gpa_b, science_gpa_b,
#   # nepali_gpa_e, english_gpa_e, math_gpa_e, science_gpa_e,
#   all_gpa_b, all_gpa_e,
#   fscore_f1_b:fscore_f3_e)
# 
# dat_mi <- mice::mice(dat_s_mi, m = 5, seed = 1234)
# 
# # x <- complete(dat_mi, 4)
# # View(filter(x, sch_id == 3))
# 
# # multiple imputation on data including only deaf students
# dat_s_deaf <- dat_s |> filter(student_type == "Deaf")
# dat_mi_deaf <- mice::mice(dat_s_deaf, m = 5, seed = 1234)
```

# Descriptives

```{r}
# grade 11 and 12 in Baglung on have 3 and 5 deaf kids
dat_s |> group_by(class_id) |> summarise(
  n_treat = sum(treated_int),
  n_control = sum(treated_int != 1)
) |> View()

dat_s_deaf |> group_by(class_id) |> summarise(
  n_treat = sum(treated_int),
  n_control = sum(treated_int != 1)
) |> View()

# most of the hearing kids are in grade 11 and 12 in Baglung
dat_s |> filter(class_id %in% 1:7) |> group_by(class_id) |> 
  summarise(
    n_hearing = sum(student_type == "Hearing", na.rm = T),
    n_deaf = sum(student_type == "Deaf", na.rm = T))

# 7 NAs in student_type (because of no baseline data)
table(dat_s$student_type, useNA = "always")
dat_s |> filter(is.na(student_type) == T) |> View()

## We can include a school fixed effect to account for whether hearing kids are present in school
```

# Frequentist model (NOT USED)

Complex mixed-effect models (i.e., those with a large number of variance-covariance parameters) frequently result in singular fits, i.e. estimated variance-covariance matrices with less than full rank.

While singular models are statistically well defined (it is theoretically sensible for the true maximum likelihood estimate to correspond to a singular fit), there are real concerns that (1) singular fits correspond to overfitted models that may have poor power; (2) chances of numerical problems and mis-convergence are higher for singular models (e.g. it may be computationally difficult to compute profile confidence intervals for such models); (3) standard inferential procedures such as Wald statistics and likelihood ratio tests may be inappropriate.

Therefore, we use a fully Bayesian method that both regularizes the model via informative priors and gives estimates and credible intervals for all parameters that average over the uncertainty in the random effects parameters (Gelman and Hill 2006, McElreath 2015; MCMCglmm, rstanarm and brms packages).

```{r}
fit_integrity_esteem_freq <- with(
  data = dat_mi,
  exp = lmer(self_integrity_esteem_e ~ self_integrity_esteem_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id))
    )

summary(pool(fit_integrity_esteem_freq))


fit_belonging_freq <- with(
  data = dat_mi,
  exp = lmer(belonging_e ~ belonging_b + treated_int +
    class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id))
)

summary(pool(fit_belonging_freq))


fit_worry_freq <- with(
  data = dat_mi,
  exp = lmer(worry_e ~ worry_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id))
)

summary(pool(fit_worry_freq))


fit_stereotype_freq <- with(
  data = dat_mi,
  exp = lmer(stereotype_e ~ stereotype_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id))
)

summary(pool(fit_stereotype_freq))


fit_academic_stress_freq <- with(
  data = dat_mi,
  exp = lmer(academic_stress_e ~ academic_stress_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id))
)

summary(pool(fit_academic_stress_freq))

```





# MI using average construct scores (CAVEAT!LOW RELIABILITY!)
## Prior predictive checks

```{r check priors}
my_prior <- prior("normal(0, 1)", class = "b")

my_prior_pos <- prior("normal(0, 1)", class = "b") +
    prior("normal(0.145, 0.2175)", class = "b", coef = "treated_int")

my_prior_neg <- prior("normal(0, 1)", class = "b") +
    prior("normal(-0.145, 0.2175)", class = "b", coef = "treated_int")


validate_prior(
    my_prior,
               self_integrity_esteem_e ~ self_integrity_esteem_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s)
```

```{r prior predictive checks}
fit_integrity_esteem_PD <- brm(
  self_integrity_esteem_e ~ self_integrity_esteem_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s,
  prior = my_prior_pos,
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

pp_check(fit_integrity_esteem_PD) + list(theme(text=element_text(size=rel(5), family = "sans"))) + xlim(-50, 50)

# plot.kdensity(dat_s$self_integrity_esteem_b)

fit_belonging_PD <- brm(
  belonging_e ~ belonging_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s,
  prior = my_prior_pos,
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

pp_check(fit_belonging_PD) + list(theme(text=element_text(size=rel(5), family = "sans"))) +  xlim(-50, 50)


fit_worry_PD <- brm(
  worry_e ~ worry_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s,
  prior = my_prior_neg,
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

pp_check(fit_worry_PD) + list(theme(text=element_text(size=rel(5), family = "sans"))) +  xlim(-50, 50)

fit_stereotype_PD <- brm(
  stereotype_e ~ stereotype_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s,
  prior = my_prior_neg, 
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

pp_check(fit_stereotype_PD) + list(theme(text=element_text(size=rel(5), family = "sans"))) +  xlim(-50, 50)


fit_academic_stress_PD <- brm(
  academic_stress_e ~ academic_stress_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s,
  prior = my_prior_neg, 
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

pp_check(fit_academic_stress_PD) 
```

## Bayesian model (all students)

```{r Bayesian model (all students)}
fit_integrity_esteem <- brm_multiple(
  self_integrity_esteem_e ~ self_integrity_esteem_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi,
  prior = my_prior_pos,
  chains = 4,
  seed = 1234
)


fit_belonging <- brm_multiple(
  belonging_e ~ belonging_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi,
  prior = my_prior_pos,
  chains = 4,
  seed = 1234
)

fit_worry <- brm_multiple(
  worry_e ~ worry_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi,
  prior = my_prior_neg,
  chains = 4,
  seed = 1234
)

fit_stereotype <- brm_multiple(
  stereotype_e ~ stereotype_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi,
  prior = my_prior_neg, 
  chains = 4,
  seed = 1234
)

fit_academic_stress <- brm_multiple(
  academic_stress_e ~ academic_stress_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi,
  prior = my_prior_neg,
  chains = 4,
  seed = 1234
)

# fit_threat_others2others <- brm_multiple(
#   threat_others2others_e ~ threat_others2others_b + treated_int +
#     class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
#     father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
#     (treated_int | class_id),
#   dat_mi,
#   prior = my_prior_neg,
#   chains = 4,
#   seed = 1234
# )
# 
# fit_threat_me2others <- brm_multiple(
#   threat_me2others_e ~ threat_me2others_b + treated_int +
#     class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
#     father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
#     (treated_int | class_id),
#  dat_mi,
#   prior = my_prior_neg,
#   chains = 4,
#   seed = 1234
# )
# 
# fit_threat_others2me <- brm_multiple(
#   threat_others2me_e ~ threat_others2me_b + treated_int +
#     class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
#     father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
#     (treated_int | class_id),
#   dat_mi,
#   prior = my_prior,
#   chains = 4,
#   seed = 1234
# )
```

```{r Bayesian model (all students) summary}

# https://discourse.mc-stan.org/t/brm-multiple-not-converging-though-separate-brm-models-do/8740/2

# fit_integrity_esteem$rhats
# prior_summary(fit_integrity_esteem)
summary(fit_integrity_esteem)
summary(fit_belonging)
summary(fit_stereotype)
summary(fit_worry)
summary(fit_academic_stress)

# posterior predictive checks suggest pretty good fit
pp_check(fit_integrity_esteem)
pp_check(fit_belonging)
pp_check(fit_stereotype)
pp_check(fit_worry)
pp_check(fit_academic_stress)

# loo suggests good convergence
loo_fit_integrity_esteem <- loo(fit_integrity_esteem, reloo = T)
loo_fit_belonging <- loo(fit_belonging, reloo = T)
loo_fit_stereotype <- loo(fit_stereotype, reloo = T)
loo_fit_worry <- loo(fit_worry, reloo = T)
loo_fit_academic_stress <- loo(fit_academic_stress, reloo = T)


# "marginal" finding on treatment reducing perceived stereotype threat
hypothesis(fit_integrity_esteem, "treated_int > 0") # BF = 0.77; PP = 0.44
hypothesis(fit_belonging, "treated_int > 0") # BF = 0.17; PP = 0.14
hypothesis(fit_stereotype, "treated_int < 0") # BF = 3.32; PP = 0.77
hypothesis(fit_worry, "treated_int < 0") # BF = 1.34; PP = 0.57
hypothesis(fit_academic_stress, "treated_int < 0") # 1.37; PP = 0.58

# plot(fit, pars = "treated_int")

# 95% high-density interval for reporting
hdi(fit_integrity_esteem, ci = 0.95) # [-0.24, 0.21]
hdi(fit_belonging, ci = 0.95) # [-0.38, 0.12]
hdi(fit_stereotype, ci = 0.95) # [-0.36, 0.14]
hdi(fit_worry, ci = 0.95) # [-0.25, 0.20]
hdi(fit_academic_stress, ci = 0.95) # [-0.26, 0.21]


# posterior draws of Cohen's d effect size
summary(get.posterior.treat.d(fit_integrity_esteem))
summary(get.posterior.treat.d(fit_belonging))
summary(get.posterior.treat.d(fit_stereotype))
summary(get.posterior.treat.d(fit_worry))
summary(get.posterior.treat.d(fit_academic_stress))

```

```{r prior sensitivity analysis}
# weakly informative prior for all
model_list_p1 <- get.model.results.secondary()

model_list_p1_par_treat <- posterior_samples(model_list_p1[[1]], "treated_int")

plot(model_list_p1[[1]], "treated_int")

hypothesis(model_list_p1[[1]], "treated_int > 0")
hypothesis(model_list_p1[[2]], "treated_int > 0")
hypothesis(model_list_p1[[3]], "treated_int < 0")
hypothesis(model_list_p1[[4]], "treated_int < 0")#
hypothesis(model_list_p1[[5]], "treated_int < 0")

# informative prior for all
model_list_p2 <- get.model.results.secondary(
  my_prior_pos = prior("normal(0, 1)", class = "b") +
    prior("normal(0.145, 0.2175)", class = "b", coef = "treated_int"),
  my_prior_neg = prior("normal(0, 1)", class = "b") +
    prior("normal(-0.145, 0.2175)", class = "b", coef = "treated_int"))

model_list_p2_par_treat <- posterior_samples(model_list_p2[[4]], "treated_int")

plot(model_list_p2[[1]], "b_treated_int")
plot(model_list_p2[[2]], "b_treated_int")
plot(model_list_p2[[3]], "b_treated_int")
plot(model_list_p2[[4]], "b_treated_int")
plot(model_list_p2[[5]], "b_treated_int")

hypothesis(model_list_p2[[1]], "treated_int > 0")#
hypothesis(model_list_p2[[2]], "treated_int > 0")
hypothesis(model_list_p2[[3]], "treated_int < 0")#
hypothesis(model_list_p2[[4]], "treated_int < 0")#
hypothesis(model_list_p2[[5]], "treated_int < 0")


test <- brm(
  self_integrity_esteem_e ~ self_integrity_esteem_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s,
  prior = set_prior("normal(0, 1)", class = "b", coef = "treated_int"),
  chains = 3,
  seed = 1234
)

stan_code = stancode(model_list_p1[[1]])

```


## Bayesian model (deaf only)

```{r Bayesian model (deaf students)}
fit_integrity_esteem_deaf <- brm_multiple(
  self_integrity_esteem_e ~ self_integrity_esteem_b + treated_int +
    class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi_deaf,
  prior = my_prior_pos,
  chains = 4,
  seed = 1234
)


fit_belonging_deaf  <- brm_multiple(
  belonging_e ~ belonging_b + treated_int +
    class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi_deaf,
  prior = my_prior_pos,
  chains = 4,
  seed = 1234
)

fit_worry_deaf  <- brm_multiple(
  worry_e ~ worry_b + treated_int +
    class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi_deaf,
  prior = my_prior_neg,
  chains = 4,
  seed = 1234
)

fit_stereotype_deaf  <- brm_multiple(
  stereotype_e ~ stereotype_b + treated_int +
    class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi_deaf,
  prior = my_prior_neg, 
  chains = 4,
  seed = 1234
)

fit_academic_stress_deaf  <- brm_multiple(
  academic_stress_e ~ academic_stress_b + treated_int +
    class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_mi_deaf,
  prior = my_prior_neg,
  chains = 4,
  seed = 1234
)

# fit_threat_others2others_deaf  <- brm_multiple(
#   threat_others2others_e ~ threat_others2others_b + treated_int +
#     class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
#     father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
#     (treated_int | class_id),
#   dat_mi_deaf,
#   prior = my_prior_neg,
#   chains = 4,
#   seed = 1234
# )
# 
# fit_threat_me2others_deaf  <- brm_multiple(
#   threat_me2others_e ~ threat_me2others_b + treated_int +
#     class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
#     father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
#     (treated_int | class_id),
#   dat_mi_deaf,
#   prior = my_prior_neg,
#   chains = 4,
#   seed = 1234
# )
# 
# fit_threat_others2me_deaf  <- brm_multiple(
#   threat_others2me_e ~ threat_others2me_b + treated_int +
#     class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
#     father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
#     (treated_int | class_id),
#   dat_mi_deaf,
#   prior = my_prior,
#   chains = 4,
#   seed = 1234
# )
```

```{r Bayesian model (deaf students) summary}

# https://discourse.mc-stan.org/t/brm-multiple-not-converging-though-separate-brm-models-do/8740/2

# fit_integrity_esteem$rhats
# prior_summary(fit_integrity_esteem)
summary(fit_integrity_esteem_deaf)
summary(fit_belonging_deaf)
summary(fit_stereotype_deaf)
summary(fit_worry_deaf)
summary(fit_academic_stress_deaf)

# posterior predictive checks suggest pretty good fit
pp_check(fit_integrity_esteem_deaf)
pp_check(fit_belonging_deaf)
pp_check(fit_stereotype_deaf)
pp_check(fit_worry_deaf)
pp_check(fit_academic_stress_deaf)

# loo suggests good convergence
loo_fit_integrity_esteem_deaf <- loo(fit_integrity_esteem_deaf, reloo = T)
loo_fit_belonging_deaf <- loo(fit_belonging_deaf, reloo = T)
loo_fit_stereotype_deaf <- loo(fit_stereotype_deaf, reloo = T)
loo_fit_worry_deaf <- loo(fit_worry_deaf, reloo = T)
loo_fit_academic_stress_deaf <- loo(fit_academic_stress_deaf, reloo = T)


# "marginal" finding on treatment 1) improving self-integrity / self-esteem; 2) reducing perceived stereotype and stereotype threat; 3) reducing academic stress
hypothesis(fit_integrity_esteem_deaf, "treated_int > 0") # BF = 3.57; PP = 0.78
hypothesis(fit_belonging_deaf, "treated_int > 0") # BF = 0.33; PP = 0.25
hypothesis(fit_stereotype_deaf, "treated_int < 0") # BF = 3.03; PP = 0.75
hypothesis(fit_worry_deaf, "treated_int < 0") # BF = 8.82; PP = 0.9
hypothesis(fit_academic_stress_deaf, "treated_int < 0") # 3.16; PP = 0.76

# plot(fit, pars = "treated_int")

# 95% high-density interval for reporting
hdi(fit_integrity_esteem_deaf, ci = 0.95) # [-0.16, 0.34]
hdi(fit_belonging_deaf, ci = 0.95) # [-0.35, 0.15]
hdi(fit_stereotype_deaf, ci = 0.95) # [-0.33, 0.15]
hdi(fit_worry_deaf, ci = 0.95) # [-0.47, 0.10]
hdi(fit_academic_stress_deaf, ci = 0.95) # [-0.33, 0.16]


# posterior draws of Cohen's d effect size
summary(get.posterior.treat.d(fit_integrity_esteem_deaf))
summary(get.posterior.treat.d(fit_belonging_deaf))
summary(get.posterior.treat.d(fit_stereotype_deaf))
summary(get.posterior.treat.d(fit_worry_deaf))
summary(get.posterior.treat.d(fit_academic_stress_deaf))

# sexit reporting based on empirical benchmarks in Bakker et al., 2019 and Kraft, 2020: small = 0.05, medium = 0.15, large = 0.2

# Following the Sequential Effect eXistence and sIgnificance Testing (SEXIT) framework, we report the median of the posterior distribution and its 95% CI (Highest Density Interval), along the probability of direction (pd), the probability of significance and the probability of being large. The thresholds beyond which the effect is considered as significant (i.e., non-negligible) and large are |0.15| and |0.20| (corresponding respectively to 0.11 and 0.14 of the outcome's SD).

sexit(fit_integrity_esteem_deaf, significant = 0.15, large = 0.2)[3,] # b_treated_int (Median = 0.10, 95% CI [-0.16, 0.34]) has a 78.11% probability of being positive (> 0), 33.37% of being significant (> 0.15), and 20.11% of being large (> 0.20)

sexit(fit_belonging_deaf, significant = 0.15, large = 0.2)[3,] # b_treated_int (Median = -0.09, 95% CI [-0.35, 0.16]) has a 75.27% probability of being negative (< 0), 31.95% of being significant (< -0.15), and 20.11% of being large (< -0.20)

sexit(fit_stereotype_deaf, significant = 0.15, large = 0.2)[3,] # b_treated_int (Median = -0.08, 95% CI [-0.32, 0.16]) has a 75.16% probability of being negative (< 0), 29.09% of being significant (< -0.15), and 17.01% of being large (< -0.20)

sexit(fit_worry_deaf, significant = 0.15, large = 0.2)[3,] # b_treated_int (Median = -0.21, 95% CI [-0.47, 0.10]) has a 89.81% probability of being negative (< 0), 65.33% of being significant (< -0.15), and 53.01% of being large (< -0.20)

sexit(fit_academic_stress_deaf, significant = 0.15, large = 0.2)[3,] # b_treated_int (Median = -0.09, 95% CI [-0.33, 0.16]) has a 75.95% probability of being negative (< 0), 30.48% of being significant (< -0.15), and 18.12% of being large (< -0.20)

```

```{r prior sensitivity analysis (deaf students)}
model_list_deaf_p1 <- get.model.results.deaf.secondary()

hypothesis(model_list_deaf_p1[[1]], "treated_int > 0")
hypothesis(model_list_deaf_p1[[2]], "treated_int > 0")
hypothesis(model_list_deaf_p1[[3]], "treated_int < 0")#
hypothesis(model_list_deaf_p1[[4]], "treated_int < 0")
hypothesis(model_list_deaf_p1[[5]], "treated_int < 0")

sexit(model_list_deaf_p1[[1]], significant = 0.15, large = 0.2)[3,]
sexit(model_list_deaf_p1[[2]], significant = 0.15, large = 0.2)[3,]
sexit(model_list_deaf_p1[[3]], significant = 0.15, large = 0.2)[3,]
sexit(model_list_deaf_p1[[4]], significant = 0.15, large = 0.2)[3,]
sexit(model_list_deaf_p1[[5]], significant = 0.15, large = 0.2)[3,]

model_list_deaf_p2 <- get.model.results.deaf.secondary(
  data = dat_mi_deaf, 
  my_prior_pos = prior("normal(0, 1)", class = "b") +
    prior("normal(0.145, 0.2175)", class = "b", coef = "treated_int"),
  my_prior_neg = prior("normal(0, 1)", class = "b") +
    prior("normal(-0.145, 0.2175)", class = "b", coef = "treated_int"))

hypothesis(model_list_deaf_p2[[1]], "treated_int > 0")
hypothesis(model_list_deaf_p2[[2]], "treated_int > 0")
hypothesis(model_list_deaf_p2[[3]], "treated_int < 0")
hypothesis(model_list_deaf_p2[[4]], "treated_int < 0")
hypothesis(model_list_deaf_p2[[5]], "treated_int < 0")

```


# MI using factor scores
## Prior predictive checks

```{r}
load("/Users/michaelfive/Library/CloudStorage/GoogleDrive-wuzezhen33@gmail.com/My Drive/Nepal SA Study/Analysis/model/bayesian_model_0215.RData")
```

```{r check priors}
# priors to be tested
my_prior <- prior("normal(0, 1)", class = "b")

# my_prior_pos <- prior("normal(0, 1)", class = "b") +
#     prior("normal(0.145, 0.2175)", class = "b", coef = "treated_int")
# 
# my_prior_neg <- prior("normal(0, 1)", class = "b") +
#     prior("normal(-0.145, 0.2175)", class = "b", coef = "treated_int")

# check default priors for other parameters
validate_prior(
    my_prior,
    fscore_f1_e ~ fscore_f1_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
    (treated_int | class_id),
  dat_s)
```

```{r prior predictive checks}
fit_f1_PD <- brm(
  fscore_f1_e ~ fscore_f1_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
    (treated_int | class_id),
  dat_s,
  prior = my_prior,
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

color_scheme_set("purple")
p1 <- pp_check(fit_f1_PD, ndraws = 200) + 
  labs(title = "Prior predictive checking for the model\npredicting self-efficacy and sense of belonging in school", 
       x = "Self-esteem", 
       y = "Density") + 
  xlim(-50,50) +
  theme_classic();p1

ggsave(here::here("analysis/plots/prior_pc_f1.png"),
       p1,
       width = 6, height = 5)

#pp_check(fit_f1_PD, "stat")


# plot.kdensity(dat_s$fscore_f1_e)

fit_f2_PD <- brm(
  fscore_f2_e ~ fscore_f2_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
    (treated_int | class_id),
  dat_s,
  prior = my_prior,
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

p2 <- pp_check(fit_f2_PD, ndraws = 200) + 
  labs(title = "Prior predictive checking for the model\npredicting stereotype threat", 
       x = "Stereotype Threat", 
       y = "Density") + 
  xlim(-50,50) +
  theme_classic();p2

ggsave(here::here("analysis/plots/prior_pc_f2.png"),
       p2,
       width = 6, height = 5)


fit_f3_PD <- brm(
  fscore_f3_e ~ fscore_f3_b + treated_int +
    class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
    father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
    (treated_int | class_id),
  dat_s,
  prior = my_prior,
  chains = 4,
  seed = 1234,
  sample_prior = "only"
)

p3 <- pp_check(fit_f3_PD, ndraws = 200) + 
  labs(title = "Prior predictive checking for the model\npredicting academic stress", 
       x = "Academic Stress", 
       y = "Density") + 
  xlim(-50,50) +
  theme_classic();p3

ggsave(here::here("analysis/plots/prior_pc_f3.png"),
       p3,
       width = 6, height = 5)

p <- gridExtra::grid.arrange(p1,p2,p3, nrow = 1);p

ggsave(here::here("analysis/plots/prior_pc_combined.png"),
       p,
       width = 12, height = 4)

# The characteristics of the observed data do not seem to lie in the tails of the reference prior predictive distribution

# Prior predictive checks can also be compared with the data, but one should not expect them to be calibrated in the same way as posterior predictive checks. That would require guessing the posterior and encoding it in the prior. The goal is make sure the prior is not so wide that it will pull probability mass away from feasible values
```

## Bayesian model (all students)

### Fit models and check convergence

```{r}
set.seed(1234)
model_list_p1 <- get.fs.model.results.secondary()

# The combined model may issue false positive convergence warnings, as the MCMC chains corresponding to different datasets may not necessarily overlap, even if each of the original models did converge. 
model_list_p1[[1]]$rhats# pretty good rhats
model_list_p1[[2]]$rhats # pretty good rhats
model_list_p1[[3]]$rhats # pretty good rhats
# so there is no issue with convergence

# posterior predictive checks suggest pretty good fit
p1 <- pp_check(model_list_p1[[1]], ndraws = 200) +
  labs(title = "Posterior predictive checking for the model\npredicting self-esteem", 
       x = "Self-esteem", 
       y = "Density") + 
  xlim(-5,5) +
  theme_classic();p1

p2 <- pp_check(model_list_p1[[2]], ndraws = 200) +
  labs(title = "Posterior predictive checking for the model\npredicting stereotype threat", 
       x = "Stereotype Threat", 
       y = "Density") + 
  xlim(-5,5) +
  theme_classic();p2

p3 <- pp_check(model_list_p1[[3]], ndraws = 200) +
  labs(title = "Posterior predictive checking for the model\npredicting academic stress", 
       x = "Academic Stress", 
       y = "Density") + 
  xlim(-5,5) +
  theme_classic();p3

p <- gridExtra::grid.arrange(p1,p2,p3, nrow = 1);p

ggsave(here::here("analysis/plots/post_pc_combined.png"),
       p,
       width = 12, height = 4)

# loo suggests good predictive performance (not necessary though if I wish to focusing on interpreting the model parameters)
loo_f1 <- loo(model_list_p1[[1]], reloo = T)
loo_f2 <- loo(model_list_p1[[2]], reloo = T)
loo_f3 <- loo(model_list_p1[[3]], reloo = T)

```

### Interpret results
```{r}
# "marginal" finding on treatment reducing perceived stereotype threat
hypothesis(model_list_p1[[1]], "treated_int > 0")
hypothesis(model_list_p1[[2]], "treated_int < 0") #
hypothesis(model_list_p1[[3]], "treated_int < 0")

plot(model_list_p1[[2]], variable = "b_treated_int")

# 95% high-density interval for reporting
hdi(model_list_p1[[1]], ci = 0.89)
hdi(model_list_p1[[2]], ci = 0.89)
hdi(model_list_p1[[3]], ci = 0.89)

# posterior draws of Cohen's d effect size
hist(get.posterior.treat.d(model_list_p1[[1]]))
hist(get.posterior.treat.d(model_list_p1[[2]]))
hist(get.posterior.treat.d(model_list_p1[[3]]))

# sexit reporting based on empirical benchmarks in Bakker et al., 2019 and Kraft, 2020: small = 0.05, medium = 0.15, large = 0.2

# Following the Sequential Effect eXistence and sIgnificance Testing (SEXIT) framework, we report the median of the posterior distribution and its 95% CI (Highest Density Interval), along the probability of direction (pd), the probability of significance and the probability of being large. The thresholds beyond which the effect is considered as significant (i.e., non-negligible) and large are |0.15| and |0.20| (corresponding respectively to 0.11 and 0.14 of the outcome's SD).

sexit(model_list_p1[[1]], ci = 0.89, significant = 0.15, large = 0.2)[3,]
sexit(model_list_p1[[2]], ci = 0.89, significant = 0.15, large = 0.2)[3,]
sexit(model_list_p1[[3]], ci = 0.89, significant = 0.15, large = 0.2)[3,]

rope(model_list_p1[[1]], ci = 0.95)
rope(model_list_p1[[2]], ci = 0.95)
rope(model_list_p1[[3]], ci = 0.95)

#bayesfactor_parameters(, null = c(-1, 1))
```

## Bayesian model (deaf students)

### Fit models and check convergence

```{r}
model_list_deaf_p1 <- get.fs.model.results.deaf.secondary()

# The combined model may issue false positive convergence warnings, as the MCMC chains corresponding to different datasets may not necessarily overlap, even if each of the original models did converge. 
model_list_deaf_p1[[1]]$rhats# pretty good rhats
model_list_deaf_p1[[2]]$rhats # pretty good rhats
model_list_deaf_p1[[3]]$rhats # pretty good rhats
# so there is no issue with convergence

# posterior predictive checks suggest pretty good fit
p1 <- pp_check(model_list_deaf_p1[[1]], ndraws = 200) +
  labs(title = "Posterior predictive checking for the model\npredicting self-efficacy and sense of belonging in school (deaf students only)", 
       x = "Self-efficacy and sense of belonging in school", 
       y = "Density") + 
  xlim(-5,5) +
  theme_classic();p1

p2 <- pp_check(model_list_deaf_p1[[2]], ndraws = 200) +
  labs(title = "Posterior predictive checking for the model\npredicting stereotype threat (deaf students only)", 
       x = "Stereotype Threat", 
       y = "Density") + 
  xlim(-5,5) +
  theme_classic();p2

p3 <- pp_check(model_list_deaf_p1[[3]], ndraws = 200) +
  labs(title = "Posterior predictive checking for the model\npredicting academic stress (deaf students only)", 
       x = "Academic Stress", 
       y = "Density") + 
  xlim(-5,5) +
  theme_classic();p3

p <- gridExtra::grid.arrange(p1,p2,p3, nrow = 1);p

ggsave(here::here("analysis/plots/post_pc_combined_deaf.png"),
       p,
       width = 12, height = 4)

# loo suggests good predictive performance (not necessary though if I wish to focusing on interpreting the model parameters)
loo_f1 <- loo(model_list_deaf_p1[[1]], reloo = T)
loo_f2 <- loo(model_list_deaf_p1[[2]], reloo = T)
loo_f3 <- loo(model_list_deaf_p1[[3]], reloo = T)

```

### Interpret results
```{r}
# "marginal" finding on treatment reducing perceived stereotype threat
hypothesis(model_list_deaf_p1[[1]], "treated_int > 0")
hypothesis(model_list_deaf_p1[[2]], "treated_int < 0") #
hypothesis(model_list_deaf_p1[[3]], "treated_int < 0")

# plot(model_list_deaf_p1[[2]], variable = "b_treated_int", theme = theme_classic())

draws <- as_draws_df(model_list_deaf_p1[[1]])

plot.kdensity(draws$b_treated_int, value = 0,
              xlab = "Treatment - Control",
              main = "Posterior Distribution of the Treatment Effect on\nSelf-efficacy and Sense of Belonging in School",
              col1 = "steelblue1",
              col2 = "firebrick1")

draws <- as_draws_df(model_list_deaf_p1[[2]])

plot.kdensity(draws$b_treated_int, value = 0,
              xlab = "Treatment - Control",
              main = "Posterior Distribution of the Treatment Effect\non Stereotype Threat")

abline(v = c(-0.37, 0.06), col = "orange", lwd = 3)

plot.kdensity(draws$b_treated_int, value = 0,
              xlab = "Treatment - Control",
              main = "Posterior Distribution of the Treatment Effect\non Stereotype Threat")


abline(v = c(-0.11, 0.11), col = "orange", lwd = 2)

# Add a shaded rectangle between the lines
rect(-0.11, 0, 0.11, 4, col = rgb(1, 0.5, 0, alpha = 0.5), border = NA)


draws <- as_draws_df(model_list_deaf_p1[[3]])

plot.kdensity(draws$b_treated_int, value = 0,
              xlab = "Treatment - Control",
              main = "Posterior Distribution of the Treatment Effect \non Academic Stress")


plot.kdensity(value = 0,
              xlab = "Treatment - Control",
              ylab = "Density",
              main = "Prior Distribution of the Treatment Effect\non Stereotype Threat (Normal(0, 1))",
              plot.prior = T)


# 95% high-density interval for reporting
hdi(model_list_deaf_p1[[1]], ci = 0.89)
hdi(model_list_deaf_p1[[2]], ci = 0.89)
hdi(model_list_deaf_p1[[3]], ci = 0.89)

# posterior draws of Cohen's d effect size
hist(get.posterior.treat.d(model_list_deaf_p1[[1]]))
hist(get.posterior.treat.d(model_list_deaf_p1[[2]]))
hist(get.posterior.treat.d(model_list_deaf_p1[[3]]))

# sexit reporting based on empirical benchmarks in Bakker et al., 2019 and Kraft, 2020: small = 0.05, medium = 0.15, large = 0.2

# Following the Sequential Effect eXistence and sIgnificance Testing (SEXIT) framework, we report the median of the posterior distribution and its 95% CI (Highest Density Interval), along the probability of direction (pd), the probability of significance and the probability of being large. The thresholds beyond which the effect is considered as significant (i.e., non-negligible) and large are |0.15| and |0.20| (corresponding respectively to 0.11 and 0.14 of the outcome's SD).

sexit(model_list_deaf_p1[[1]], significant = 0.15, large = 0.2, ci = 0.89)[3,]
sexit(model_list_deaf_p1[[2]], significant = 0.15, large = 0.2, ci = 0.89)[3,]
sexit(model_list_deaf_p1[[3]], significant = 0.15, large = 0.2, ci = 0.89)[3,]


rope(model_list_deaf_p1[[1]], ci = 0.95)
rope(model_list_deaf_p1[[2]], ci = 0.95)
rope(model_list_deaf_p1[[3]], ci = 0.95)
```

### Moderation effect
```{r}
fit_f2_deaf_mod <- brm_multiple(
    fscore_f2_e ~ fscore_f2_b + treated_int * age_b +
      class_size + grade + gender + father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
    dat_mi_deaf,
    prior = my_prior, 
    chains = 4,
    seed = 1234
  )

hypothesis(fit_f2_deaf_mod, "treated_int:age_b > 0")

ic <- list(treated_int = c(0, 1))

conditional_effects(fit_f2_deaf_mod, 
                      effects = "age_b:treated_int",
                      int_conditions = ic)


fit_f2_deaf <- add_criterion(model_list_deaf_p1[[2]], c("loo", "waic"))
fit_f2_deaf_mod <- add_criterion(fit_f2_deaf_mod, c("loo", "waic"))

loo_compare(fit_f2_deaf, fit_f2_deaf_mod,
            criterion = "loo")

loo_compare(fit_f2_deaf, fit_f2_deaf_mod,
            criterion = "waic")

```

```{r}
df <- dat_s |> 
  group_by(treated_int) |> 
  summarise(m_b = mean(fscore_f2_b, na.rm = T),
            se_b = sd(fscore_f2_b, na.rm = T)/sqrt(length(fscore_f2_b)),
            m_e = mean(fscore_f2_e, na.rm = T),
            se_e = sd(fscore_f2_e, na.rm = T)/sqrt(length(fscore_f2_e))
            )

df <- df |> 
  pivot_longer(cols = m_b:se_e,
               names_to = c("stat", "time"),
               names_pattern = "(.*)_(.*)",
               values_to = "value")

df <- df |> 
  pivot_wider(names_from = "stat", values_from = "value")

df <- df |> 
  mutate(treated_int = ifelse(treated_int == 1,
                              "Treatment",
                              "Control")) |> 
  rename(Condition = treated_int)

df <- df |> 
  mutate(time = ifelse(time == "b", "Baseline", "Endline"))

ggplot(data = df,
       aes(x = time, y = m, group = Condition,
           color = Condition)) +
  geom_line(position=position_dodge(0.05))+
  geom_point(size = 3, position=position_dodge(0.05)) +
  geom_errorbar(aes(ymin=m-se, ymax=m+se), width=.08,
                 position=position_dodge(0.05)) +
  labs(x = "", y = "Stereotype Threat\n",
       title = "Average Stereotype Threat at Baseline and Endline\nby Treatment Conditions",
       caption = "(Each error bar shows the standard error of the group mean.)") +
  theme_classic() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5)) +
   scale_color_manual(values=c('firebrick1','steelblue1'))

```

# Complete-case GPA data

```{r}
my_prior <- prior("normal(0, 1)", class = "b")
# my_prior <- prior("normal(0, 1)", class = "b") + 
#     prior("normal(0.145, 0.2175)", coef = "treated_int")

# check default priors for other parameters
validate_prior(
    my_prior,
    nepali_gpa_e ~ nepali_gpa_b + treated_int +
      class_size + grade + gender + age_b + father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
  dat_s)
```

```{r check missing value}
test <- dat_s |> select(
      st_id, all_gpa_e, all_gpa_b, treated_int, class_size, grade, gender, age_b, father_edu_f, mother_edu_f, father_occ_salary, mother_occ_salary, adult_members, siblings, duration_int, sch_id, class_id)

md.pattern(test, rotate.names = TRUE)

View(dat_fs |> filter(st_id == "SCH1_GR6_ST10"))


# Tests the null hypothesis that the missing data is Missing Completely At Random (MCAR). A p.value of less than 0.05 is usually interpreted as being that the missing data is not MCAR (i.e., is either Missing At Random or non-ignorable).

test <- dat_s |> select(
      st_id, all_gpa_e, all_gpa_b, treated_int, class_size, grade, gender, age_b, father_edu_f, mother_edu_f, father_occ_salary, mother_occ_salary, adult_members, siblings, duration_int)


#   statistic    df p.value missing.patterns
#       <dbl> <dbl>   <dbl>            <int>
# 1      199.   171  0.0677               14
naniar::mcar_test(test)


#   statistic    df p.value missing.patterns
#       <dbl> <dbl>   <dbl>            <int>
# 1     5428.  5269  0.0618              117
naniar::mcar_test(dat_s |> select(-sch_id, -class_id))

# So the missing data is MCAR.
```

```{r GPA descriptives}
test <- dat_s |> ungroup() |>  select(treated_int, class_id, all_gpa_b, all_gpa_e)

test <- test |> pivot_longer(all_gpa_b:all_gpa_e, names_to = "wave", values_to = "gpa", names_pattern = ".*_([be])$")

test <- test |> 
  group_by(class_id, treated_int, wave) |> 
  summarise(
    gpa_m = mean(gpa, na.rm = T),
    gpa_se = sd(gpa, na.rm = T) / sqrt(length(gpa))
  )
  
ggplot(test, aes(x = wave, y = gpa_m, fill = factor(treated_int))) + 
  geom_bar(stat="identity", color="black", 
           position=position_dodge()) +
  geom_errorbar(aes(ymin=gpa_m - gpa_se, ymax = gpa_m + gpa_se), width=.2,
                 position=position_dodge(.9)) + 
  scale_y_continuous(limits = c(0, 4)) +
  facet_wrap(~ class_id) +
  theme_bw()
```


```{r GPA as outcome all student}

model_list_gpa_p1 <- get.model.results.primary(
  data = dat_s, 
  my_prior = prior("normal(0, 1)", class = "b")
)

model_list_gpa_p2 <- get.model.results.primary(
  data = dat_s, 
  my_prior = prior("normal(0, 1)", class = "b") + 
    prior("normal(0.145, 0.2175)", coef = "treated_int")
)

hypothesis(model_list_gpa_p1[[1]], "treated_int > 0")
hypothesis(model_list_gpa_p1[[2]], "treated_int > 0")
hypothesis(model_list_gpa_p1[[3]], "treated_int > 0")
hypothesis(model_list_gpa_p1[[4]], "treated_int > 0")
hypothesis(model_list_gpa_p1[[5]], "treated_int > 0")


test <- bayesfactor_parameters(
  model_list_gpa_p1[[5]], 
  null = 0,
  direction = ">")

library(see)
plot(test)

summary(fit_all)

draws <- as_draws_df(model_list_gpa_p1[[5]])

plot.kdensity(draws$b_treated_int, value = 0,
              xlab = "Treatment - Control",
              main = "Posterior Distribution of the Treatment Effect on Overall GPA",
              col1 = "steelblue1",
              col2 = "firebrick1")

# consider es = 0.01 as negligible
rope(model_list_gpa_p1[[5]], ci = 0.95, 
     range = c(-sd(dat_s$all_gpa_e, na.rm = T) * 0.01, 
               sd(dat_s$all_gpa_e, na.rm = T) * 0.01))

# using the empirical benchmark in Kraft (2020)
sexit(model_list_gpa_p1[[5]], significant = 0.05 * sd(dat_s$all_gpa_e, na.rm = T), large = 0.2 * sd(dat_s$all_gpa_e, na.rm = T), ci = 0.95)[3,]
```

### Moderation effect (prior performance)

```{r}
# create low-performing variable
dat_s <- dat_s |> 
  group_by(class_id) |> 
  mutate(low_performing = as.numeric(all_gpa_b <= median(all_gpa_b)))
```

```{r}
fit_all_interaction_low_performance <- brm(
    all_gpa_e ~ all_gpa_b + treated_int * low_performing +
      class_size + grade + gender + age_b + 
      father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
    data = dat_s,
    prior = my_prior, 
    chains = 4,
    seed = 1234,
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15)
  )

hypothesis(fit_all_interaction_low_performance, "treated_int > 0")

hypothesis(fit_all_interaction_low_performance, "treated_int:low_performing < 0")
```

```{r}
fit_all_interaction_age <- brm(
    all_gpa_e ~ all_gpa_b + treated_int * age_b +
      class_size + grade + gender + 
      father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
    data = dat_s,
    prior = my_prior, 
    chains = 4,
    seed = 1234,
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15)
  )

hypothesis(fit_all_interaction_age, "treated_int > 0")

hypothesis(fit_all_interaction_age, "treated_int:age_b < 0")
```

```{r}
fit_all_interaction_grade <- brm(
    all_gpa_e ~ all_gpa_b + treated_int * grade +
      class_size + age_b + gender + 
      father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
    data = dat_s,
    prior = my_prior, 
    chains = 4,
    seed = 1234,
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15)
  )

hypothesis(fit_all_interaction_grade, "treated_int > 0")
```

```{r}
fit_all_interaction_gender <- brm(
    all_gpa_e ~ all_gpa_b + treated_int * gender + grade +
      class_size + age_b + gender + 
      father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
    data = dat_s,
    prior = my_prior, 
    chains = 4,
    seed = 1234,
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15)
  )

hypothesis(fit_all_interaction_gender, "treated_int > 0")
hypothesis(fit_all_interaction_gender, "treated_int:genderMale < 0")
```

### Moderation effect (psychological threat)

Interestingly, the affirmation effect is more pronounced for deaf students experiencing less stereotype threat (or psychological threat in general) at baseline.

Ferrer & Cohen (2018) mentioned that "for self-affirmation to be beneficial, there must be a threat to self-adequacy or self-integrity and, moreover, that psychological threat must impede behavior change." Therefore, it is reasonable to think that self-affirmation works better when there are more threats present (and especially when these threats impede adaptive behavior). 

In our study context, it is unlikely that stereotype threat "facilitates" adaptive outcomes since it is a major source of stress among deaf students. Therefore, the finding that the treatment effect is larger for deaf students experiencing less stereotype threat may arise due to uniqueness of the population and context. It is possible that for deaf students, there is a pervasive psychological threat that is salient in all aspects of their life. Those experiencing too much threat may not benefit much from a brief reflection exercise, while those experiencing relatively less threat (but still much more compared to hearing students) may be the proper target of self-affirmation.

Additionally, being in the poor-performing group at baseline does not moderate the treatment effect. This may again speak to the fact that for this particular population, affirmation seems to affect performance directly through alleviating stereotype threat.

*Composite psychological threat (average of all three factors)*

```{r}
dat_s$fscore_f1_b_rev <- -dat_s$fscore_f1_b

dat_s$psych_threat <- rowMeans(dat_s[, c("fscore_f1_b_rev", "fscore_f2_b", "fscore_f2_b")], na.rm = T)

hist(dat_s$psych_threat)

fit_all_interaction_psych_threat <- brm(
    all_gpa_e ~ all_gpa_b + treated_int * psych_threat + gender + grade +
      class_size + age_b + gender + 
      father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
    data = dat_s,
    prior = my_prior, 
    chains = 4,
    seed = 1234,
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15))


hypothesis(fit_all_interaction_psych_threat, "treated_int > 0")
hypothesis(fit_all_interaction_psych_threat, "treated_int:psych_threat < 0")

# consider es = 0.01 as negligible
rope(fit_all_interaction_psych_threat, ci = 0.95, 
     range = c(-sd(dat_s$all_gpa_e, na.rm = T) * 0.01, 
               sd(dat_s$all_gpa_e, na.rm = T) * 0.01))

# using the empirical benchmark in Kraft (2020)
sexit(fit_all_interaction_psych_threat, significant = 0.05 * sd(dat_s$all_gpa_e, na.rm = T), large = 0.2 * sd(dat_s$all_gpa_e, na.rm = T), ci = 0.95)[3,]


interact_plot(model = fit_all_interaction_psych_threat, 
              pred = "treated_int", 
              modx = "psych_threat",
              legend.main = "Psychological Threat",
              pred.labels = c("Control", "Treatment"),
              x.label = "\nTreatment Condition",
              y.label = "Core Course GPA\n")
```

*Stereotype threat only*

```{r}

hist(dat_s$fscore_f2_b)

fit_all_interaction_stereotype_threat <- brm(
    all_gpa_e ~ all_gpa_b + treated_int * fscore_f2_b + gender + grade +
      class_size + age_b + gender + 
      father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + sch_id +
      (treated_int | class_id),
    data = dat_s,
    prior = my_prior, 
    chains = 4,
    seed = 1234,
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15))


hypothesis(fit_all_interaction_stereotype_threat, "treated_int > 0")
hypothesis(fit_all_interaction_stereotype_threat, "treated_int:fscore_f2_b < 0")

# consider es = 0.01 as negligible
rope(fit_all_interaction_stereotype_threat, ci = 0.95, 
     range = c(-sd(dat_s$all_gpa_e, na.rm = T) * 0.01, 
               sd(dat_s$all_gpa_e, na.rm = T) * 0.01))

# using the empirical benchmark in Kraft (2020)
sexit(fit_all_interaction_stereotype_threat, significant = 0.05 * sd(dat_s$all_gpa_e, na.rm = T), large = 0.2 * sd(dat_s$all_gpa_e, na.rm = T), ci = 0.95)[3,]


interact_plot(model = fit_all_interaction_stereotype_threat, 
              pred = "treated_int", 
              modx = "fscore_f2_b",
              legend.main = "Stereotype Threat",
              pred.labels = c("Control", "Treatment"),
              x.label = "\nTreatment Condition",
              y.label = "Core Course GPA\n")
```

# Mediation models

```{r}
# Fit Bayesian mediation model in brms
  fit_stereotype <- brm_multiple(
    stereotype_e ~ stereotype_b + treated_int +
      class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f +
      father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int +
      (treated_int | class_id),
    data,
    prior = my_prior_neg, 
    chains = 4,
    seed = 1234
  )

# Mediator model
mediator_model <- bf(fscore_f2_e ~ fscore_f2_b + treated_int + class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f + father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + (treated_int | class_id))

# Outcome model with mediator (fscore_f2_e) included
outcome_model <- bf(all_gpa_e ~ all_gpa_b + fscore_f2_e + treated_int + class_size + grade + gender + age_b + student_type + father_edu_f + mother_edu_f + father_occ_salary + mother_occ_salary + adult_members + siblings + duration_int + (treated_int | class_id))

# Fit the Bayesian mediation model
mediation_model <- brm(mediator_model + outcome_model + set_rescor(FALSE),
                       data = dat_s, 
                       prior = my_prior,
                       chains = 4,
                       seed = 1234)

# not mediated through stereotype threat
mediation(mediation_model, method = "HDI")
```

